{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import os\n",
    "import re\n",
    "\n",
    "def read_data(sheet):\n",
    "    # Find the last row with data in column A\n",
    "    last_row = sheet.max_row\n",
    "    for row in range(last_row, 2, -1):\n",
    "        if sheet.cell(row=row, column=1).value is not None:\n",
    "            last_row = row\n",
    "            break\n",
    "\n",
    "    data_range = f'A3:O{last_row}'\n",
    "    data_range_values = sheet[data_range]\n",
    "    data = [[cell.value for cell in row] for row in data_range_values]\n",
    "    return data\n",
    "\n",
    "def extract_date_from_filename(filename):\n",
    "    # Modify the regular expression to match your filename pattern\n",
    "    # For example, if your filename is like \"StaffPerformanceOverviewCR06-09-23.xlsx\"\n",
    "    # and you want to extract \"06-09-23\", you can use r'\\d{2}-\\d{2}-\\d{2}'\n",
    "    pattern = r'\\d{2}-\\d{2}-\\d{2}'\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def spo_adjustment(spoCR_path, spoNH_path):\n",
    "\n",
    "    #Library Importation\n",
    "    import openpyxl\n",
    "    from openpyxl import load_workbook\n",
    "    from openpyxl.styles import NamedStyle\n",
    "    from collections import defaultdict\n",
    "    from openpyxl.utils import get_column_letter\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import re\n",
    "\n",
    "    #Loading Workbooks\n",
    "    wb1 = load_workbook (spoCR_path)\n",
    "    wb2 = load_workbook(spoNH_path)\n",
    "    ws1 = wb1.active\n",
    "    ws2 = wb2.active\n",
    "\n",
    "    #Appending Data To One Workbook\n",
    "    for row in ws2.iter_rows(min_row=2, values_only=True): \n",
    "        ws1.append(row)\n",
    "\n",
    "    date_match = re.search(r'(\\d{2}-\\d{2}-\\d{2})', spoCR_path)\n",
    "    if date_match:\n",
    "        date = date_match.group(1)\n",
    "\n",
    "    adjusted_filename = f'merged_spo_{date}.xlsx'\n",
    "\n",
    "    # Define the folder path where you want to save the merged reports\n",
    "    merged_SPO_folder = r'Reports Folder/Staff Performance Overview/Merged Reports SPO'\n",
    "\n",
    "    # Construct the full path for the merged file\n",
    "    merged_file_path = os.path.join(merged_SPO_folder, adjusted_filename)\n",
    "\n",
    "    # Save the merged workbook to the specified absolute path\n",
    "    wb1.save(merged_file_path)\n",
    "    wb1.close()\n",
    "    wb2.close()\n",
    "\n",
    "    adjusted_workbook = openpyxl.load_workbook(merged_file_path)\n",
    "    adjusted_sheet = adjusted_workbook.active\n",
    "\n",
    "    def remove_labels(sheet):\n",
    "        # Create a dictionary to keep track of row indices for each 'New' value\n",
    "        new_rows = {}\n",
    "    \n",
    "        # Iterate through rows in reverse order to safely delete rows\n",
    "        for row_index in range(sheet.max_row, 1, -1):\n",
    "            cell_value = sheet.cell(row=row_index, column=3).value\n",
    "            if cell_value == 'New':\n",
    "                if cell_value not in new_rows:\n",
    "                    new_rows[cell_value] = [row_index]\n",
    "                else:\n",
    "                    new_rows[cell_value].append(row_index)\n",
    "\n",
    "        # Iterate through the dictionary and delete the second occurrence of 'New'\n",
    "        for value, indices in new_rows.items():\n",
    "            if len(indices) > 1:\n",
    "                sheet.delete_rows(indices[0], 1)\n",
    "\n",
    "    # Call the function to remove specific rows from the sheet\n",
    "    remove_labels(adjusted_sheet)\n",
    "\n",
    "    # Save the updated workbook after removing labels\n",
    "    adjusted_workbook.save(merged_file_path)\n",
    "\n",
    "    # Define the column letter you want to update (e.g., column A)\n",
    "    column_letter = 'E'\n",
    "\n",
    "    # Define the value to be replaced and its corresponding replacement\n",
    "    old = \"NA\"\n",
    "    new = \"0\"\n",
    "\n",
    "    # Get the column index from the column letter\n",
    "    column_index = ord(column_letter) - ord('A') + 1\n",
    "\n",
    "    # Loop through the cells in the selected column and replace the old value with the new value\n",
    "    for row in adjusted_sheet.iter_rows(min_row=3, min_col=column_index, max_col=column_index):\n",
    "        cell = row[0]\n",
    "        if cell.value == old:\n",
    "            cell.value = new\n",
    "\n",
    "    # Create named style for the whole number format\n",
    "    whole_number_style = NamedStyle(name=\"whole_number\", number_format=\"0\")\n",
    "\n",
    "    # Columns that need to be formatted as a whole number (example: columns A, B, and D)\n",
    "    columns_to_format = ['B', 'C', 'D']  # Replace with the letters of the columns you want to format\n",
    "\n",
    "    # Apply the named style to each cell in the selected columns\n",
    "    for column_letter in columns_to_format:\n",
    "        for cell in adjusted_sheet[column_letter]:\n",
    "            cell.style = whole_number_style\n",
    "\n",
    "    Decimal_Number_Style = NamedStyle(name=\"decimal\", number_format=\"#,##0.00\")\n",
    "\n",
    "    columns_to_format = ['E', 'F', 'G', 'H','I','J','K','L','M','N','O']\n",
    "\n",
    "    for column_letter in columns_to_format:\n",
    "        for cell in adjusted_sheet[column_letter]:\n",
    "            cell.style = Decimal_Number_Style\n",
    "\n",
    "    adjusted_workbook.save(merged_file_path)\n",
    "    adjusted_workbook.close()\n",
    "\n",
    "    # Define custom functions for columns 14 and 15 based on columns 2, 3, and 4\n",
    "    def calculate_AvgbillN(row):\n",
    "    # Net Average Bill\n",
    "        if row['Visits'] != 0:\n",
    "            return row['TotalN'] / row['Visits']\n",
    "        else:\n",
    "            return 0  # Return a default value when 'Visits' is zero\n",
    "\n",
    "    def calculate_AvgbillT(row):\n",
    "    # Total Average Bill\n",
    "        if row['Visits'] != 0:\n",
    "            return row['TotalT'] / row['Visits']\n",
    "        else:\n",
    "            return 0  # Return a default value when 'Visits' is zero\n",
    "\n",
    "    adjusted_workbook = openpyxl.load_workbook(merged_file_path)\n",
    "    adjusted_worksheet = adjusted_workbook.active\n",
    "\n",
    "    # Read data from the fourth_adjust_sheet\n",
    "    data = read_data(adjusted_worksheet)  # Automatically reads data starting from A3\n",
    "\n",
    "    # Create a DataFrame with all the data\n",
    "    df = pd.DataFrame(data, columns=['EmployeeID', 'Visits', 'New', 'RQs', 'Rat', 'ServiceN', 'ServiceT', 'SeriesN', \n",
    "                                    'SeriesT', 'ProductsN', 'ProductsT', 'TotalN', 'TotalT', 'AvgbillN', 'AvgbillT'])\n",
    "\n",
    "    # Get the union of EmployeeIDs\n",
    "    all_employee_ids = set(df['EmployeeID'])\n",
    "\n",
    "    # Create a DataFrame with all EmployeeIDs\n",
    "    df_all_employees = pd.DataFrame({'EmployeeID': list(all_employee_ids)})\n",
    "\n",
    "   # Convert the 'EmployeeID' column to string in both dataframes\n",
    "    df_all_employees['EmployeeID'] = df_all_employees['EmployeeID'].astype(str)\n",
    "    df['EmployeeID'] = df['EmployeeID'].astype(str)\n",
    "   \n",
    "    # Merge the original data with the DataFrame containing all EmployeeIDs (outer merge)\n",
    "    merged_data = pd.merge(df_all_employees, df, on='EmployeeID', how='left')\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    merged_data.fillna(0, inplace=True)\n",
    "\n",
    "    # Convert 'Data4', 'Data13', and 'Data14' columns to numeric type (ignore errors)\n",
    "    merged_data['Rat'] = pd.to_numeric(merged_data['Rat'], errors='coerce')\n",
    "    merged_data['AvgbillN'] = pd.to_numeric(merged_data['AvgbillN'], errors='coerce')\n",
    "    merged_data['AvgbillT'] = pd.to_numeric(merged_data['AvgbillT'], errors='coerce')\n",
    "\n",
    "    # Consolidate data based on EmployeeID and calculate the sum for each of the columns 2 to 13\n",
    "    consolidated_data = merged_data.groupby('EmployeeID', as_index=False).agg({\n",
    "        'Visits': 'sum',\n",
    "        'New': 'sum',\n",
    "        'RQs': 'sum',\n",
    "        'Rat': 'sum',\n",
    "        'ServiceN': 'sum',\n",
    "        'ServiceT': 'sum',\n",
    "        'SeriesN': 'sum',\n",
    "        'SeriesT': 'sum',\n",
    "        'ProductsN': 'sum',\n",
    "        'ProductsT': 'sum',\n",
    "        'TotalN': 'sum',\n",
    "        'TotalT': 'sum',\n",
    "        'AvgbillN': 'sum',\n",
    "        'AvgbillT': 'sum'})\n",
    "\n",
    "    # Calculate the average for Data4, Data13 columns for each individual employee\n",
    "    consolidated_data['Rat'] = consolidated_data['Rat'] / 2\n",
    "\n",
    "    # Calculate the values for columns 14 and 15 using the custom functions based on other columns\n",
    "    consolidated_data['AvgbillN'] = consolidated_data.apply(calculate_AvgbillN, axis=1)\n",
    "    consolidated_data['AvgbillT'] = consolidated_data.apply(calculate_AvgbillT, axis=1)\n",
    "\n",
    "    # Calculate the column letters for the new columns\n",
    "    conditional_column_letter = get_column_letter(adjusted_worksheet.max_column + 1)\n",
    "\n",
    "    # Add new column headers\n",
    "    conditional_column_header = \"Conditional Column\"\n",
    "    adjusted_worksheet[conditional_column_letter + '1'] = conditional_column_header\n",
    "\n",
    "    # Create a dictionary to store the count of employee occurrences\n",
    "    employee_count = {}\n",
    "\n",
    "    # Iterate through the rows (starting from the second row since the first row is headers)\n",
    "    for row in range(2, adjusted_worksheet.max_row + 1):\n",
    "        employee_cell = adjusted_worksheet.cell(row=row, column=1)  # Assuming employee names are in column 1 (A)\n",
    "        employee_name = employee_cell.value\n",
    "\n",
    "        if not employee_name:\n",
    "            continue\n",
    "\n",
    "        # Count the occurrences of each employee name\n",
    "        if employee_name in employee_count:\n",
    "            employee_count[employee_name] += 1\n",
    "        else:\n",
    "            employee_count[employee_name] = 1\n",
    "\n",
    "    # Populate the new conditional column based on employee count\n",
    "    for row in range(2, adjusted_worksheet.max_row + 1):\n",
    "        employee_name = adjusted_worksheet.cell(row=row, column=1).value\n",
    "        conditional_value = 2 if employee_count.get(employee_name, 0) > 1 else 1\n",
    "        adjusted_worksheet.cell(row=row, column=adjusted_worksheet.max_column, value=conditional_value)\n",
    "    \n",
    "    # Create a list to store rows to be removed\n",
    "    rows_to_remove = []\n",
    "\n",
    "    # Identify rows with a conditional value of 2 and mark them for removal\n",
    "    for row in range(2, adjusted_worksheet.max_row + 1):\n",
    "        conditional_value = adjusted_worksheet.cell(row=row, column=adjusted_worksheet.max_column).value\n",
    "        if conditional_value == 2:\n",
    "            rows_to_remove.append(row)\n",
    "\n",
    "    # Remove the marked rows in reverse order to avoid shifting issues\n",
    "    for row in reversed(rows_to_remove):\n",
    "        adjusted_worksheet.delete_rows(row)\n",
    "\n",
    "     # Keep only the first two rows as headers\n",
    "    rows_to_keep = [1, 2]\n",
    "    rows_to_delete = [row for row in range(2, adjusted_worksheet.max_row + 1) if row not in rows_to_keep]   \n",
    "\n",
    "    # Remove the non-header rows in reverse order to avoid shifting issues\n",
    "    for row in reversed(rows_to_delete):\n",
    "        adjusted_worksheet.delete_rows(row)\n",
    "\n",
    "    # Delete the conditional column\n",
    "    adjusted_worksheet.delete_cols(adjusted_worksheet.max_column)\n",
    "\n",
    "    # Determine the last row of data in the worksheet\n",
    "    last_row = adjusted_worksheet.max_row\n",
    "\n",
    "    # Put the consolidated data back into the Excel ws\n",
    "    for row_index, row_data in enumerate(consolidated_data.values):\n",
    "        for col_index, cell_value in enumerate(row_data):\n",
    "            cell = adjusted_worksheet.cell(row=last_row + 1 + row_index, column=col_index + 1)\n",
    "            cell.value = cell_value\n",
    "\n",
    "    # Save the updated workbook\n",
    "    adjusted_workbook.save(merged_file_path)\n",
    "\n",
    "# Call spo_adjustment for each batch of reports\n",
    "if __name__ == '__main__':\n",
    "# List of report batches (each batch is a list of report paths)\n",
    "    reports_folder = 'Reports Folder/Staff Performance Overview/Individual Reports'\n",
    "    report_files = os.listdir(reports_folder)\n",
    "\n",
    "    # Group report files by their extracted dates\n",
    "    date_to_reports = {}\n",
    "    for filename in report_files:\n",
    "        date = extract_date_from_filename(filename)\n",
    "        if date:\n",
    "            if date in date_to_reports:\n",
    "                date_to_reports[date].append(filename)\n",
    "            else:\n",
    "                date_to_reports[date] = [filename]\n",
    "\n",
    "    # Create report batches based on grouped dates\n",
    "    report_batches = []\n",
    "    for date, files in date_to_reports.items():\n",
    "        batch_size = 2  # You can adjust this according to your needs\n",
    "        for i in range(0, len(files), batch_size):\n",
    "            batch = files[i:i+batch_size]\n",
    "            report_batches.append(batch)\n",
    "\n",
    "    for batch in report_batches:\n",
    "        spoCR_path = os.path.join(reports_folder, batch[0])\n",
    "        spoNH_path = os.path.join(reports_folder, batch[1])\n",
    "        spo_adjustment(spoCR_path, spoNH_path)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
